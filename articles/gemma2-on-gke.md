---
title: "Gemma2 ã‚’ GKE ä¸Šã§ã„ã„æ„Ÿã˜ã«å‹•ã‹ã—ãŸã„ï¼ˆæ¨è«–ç·¨ï¼‰"
emoji: "ğŸ¤–"
type: "tech" # tech: æŠ€è¡“è¨˜äº‹ / idea: ã‚¢ã‚¤ãƒ‡ã‚¢
topics: [GCP, GoogleCloud, GKE, Gemma, ç”ŸæˆAI]
publication_name: "google_cloud_jp"
published: false
---
[Google Cloud Japan Advent Calendar 2024](https://zenn.dev/google_cloud_jp/articles/7799cce9f23cf0) ã® 3 æ—¥ç›®ï¼ˆã ã£ãŸã¯ãšï¼‰ã®è¨˜äº‹ã§ã™ã€‚  
æœ¬è¨˜äº‹ã§ã¯ã€GKE Autopilot ä¸Šã§ [Gemma2](https://blog.google/technology/developers/google-gemma-2/) ã‚’ã„ã„æ„Ÿã˜ã«å‹•çš„ã«ã‚¹ã‚±ãƒ¼ãƒ«ã™ã‚‹ã‚ˆã†ã«ãƒ›ã‚¹ãƒˆã—ã¦ã¿ã¾ã™ã€‚ä»Šå›ã¯æ¨è«–ã®ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã‚’ãƒ¡ã‚¤ãƒ³ã§æ‰±ã„ã¾ã™ã€‚  

ã¾ãŸ ãƒ¢ãƒ‡ãƒ«ã‚„æ¨è«–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ãƒ¬ã‚¤ãƒ¤ãƒ¼ã§ã®ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãªã©ã¯ï¼ˆç§ã®çŸ¥è­˜ãŒä¸è¶³ã—ã¦ã„ã‚‹ãŸã‚ï¼‰æ‰±ã‚ãšã€ã‚ãã¾ã§ã‚¤ãƒ³ãƒ•ãƒ©/ GKE ã®ãƒ¬ã‚¤ãƒ¤ãƒ¼ã§é ‘å¼µã‚Šã¾ã™ã€ãŒã‚‚ã—ç§ã®èªè­˜ãŒé–“é•ã£ã¦ã„ã‚‹éƒ¨åˆ†ã‚„ã‚‚ã£ã¨ã‚¹ãƒãƒ¼ãƒˆã«ã§ãã‚‹éƒ¨åˆ†ãªã©ã‚ã‚Œã°æŒ‡æ‘˜ã—ã¦ãã ã•ã‚‹ã¨å–œã³ã¾ã™ã€‚  

# tl;dr
* GKE Autopilot ã¯ãƒãƒ¼ãƒ‰ã®å‹•çš„ã‚¹ã‚±ãƒ¼ãƒ«ã‚„ãƒãƒãƒ¼ã‚¸ãƒ‰ Prometheus ã®æ©Ÿèƒ½ç­‰ãŒãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§æœ‰åŠ¹åŒ–ã•ã‚Œã¦ãŠã‚Šã€æ¨è«–ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ã®å‹•çš„ãªã‚¹ã‚±ãƒ¼ãƒ«ã‚’ç°¡å˜ã«æ§‹æˆã§ãã‚‹
* ML ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ãªã©ã‚µã‚¤ã‚ºãŒå¤§ãã„ã‚³ãƒ³ãƒ†ãƒŠã‚¤ãƒ¡ãƒ¼ã‚¸ã¯ã€ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚„ã‚»ã‚«ãƒ³ãƒ€ãƒªãƒ‡ã‚£ã‚¹ã‚¯ã®æ´»ç”¨ã«ã‚ˆã‚Šé«˜é€ŸåŒ–ã§ãã‚‹
* ãƒ¢ãƒ‡ãƒ«ã®æ ¼ç´å ´æ‰€ã¯ã•ã¾ã–ã¾ãªé¸æŠè‚¢ãŒã‚ã‚‹ãŒã€æ¨è«–ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ã§ã‚ã‚Œã° Hyperdisk ML ãŒãŠã™ã™ã‚

# Gemma ã¨ã¯
Gemma ã¯ Gemini ã¨åŒæ§˜ã®ç ”ç©¶ã€æŠ€è¡“ã‹ã‚‰ä½œã‚‰ã‚ŒãŸè»½é‡ãªã‚ªãƒ¼ãƒ—ãƒ³ãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚Gemini ã¨ç•°ãªã‚Šã€Google ã®è¨­å‚™ã®å¤–ã§ã‚‚ä½¿ã£ã¦ã„ãŸã ãã“ã¨ãŒå¯èƒ½ã§ã™ï¼ˆå•†ç”¨åˆ©ç”¨ã‚‚å¯ï¼‰ã€‚  
ä»Šå›ã¯æ•°ã‚ã‚‹ Gemma ãƒ•ã‚¡ãƒŸãƒªãƒ¼ã®ãªã‹ã§ã‚‚æ–°ä¸–ä»£ã®ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚‹ Gemma2 ã‚’ [GKE Autopilot](https://cloud.google.com/kubernetes-engine/docs/concepts/autopilot-overview) ä¸Šã§å‹•ã‹ã—ã¦ã¿ã¾ã™ã€‚ã€€  
GKE Autopilot ã¯ãƒ•ãƒ«ãƒãƒãƒ¼ã‚¸ãƒ‰ãª Kubernetes ã§ã€Node ã®ç®¡ç†ã‚’ã™ã‚‹ã“ã¨ãªãã‚¯ãƒ©ã‚¹ã‚¿ã®é‹ç”¨è² è·ã‚’ä¸‹ã’ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚GKE Autopilot ã§ã® GPU åˆ©ç”¨ã®ç‰¹å¾´ãªã©ã«ã¤ã„ã¦ã¯ä»¥å‰ã«ä»¥ä¸‹ã®è¨˜äº‹ã§ã¾ã¨ã‚ã¾ã—ãŸã®ã§ã€èˆˆå‘³ã®ã‚ã‚‹æ–¹ã¯ã”è¦§ã«ãªã£ã¦ãã ã•ã„ã€‚  
https://zenn.dev/google_cloud_jp/articles/gke-autopilot-gpu-101

## ãªãœ Gemma ã‚’ GKE ä¸Šã§å‹•ã‹ã—ãŸã„ã®ã‹
Gemma ãªã©ã‚ªãƒ¼ãƒ—ãƒ³ãƒ¢ãƒ‡ãƒ«ã‚’è‡ªå‰ã§ãƒ›ã‚¹ãƒˆã™ã‚‹ãƒ¢ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ã¨ã—ã¦ã¯ä»¥ä¸‹ãŒè€ƒãˆã‚‰ã‚Œã¾ã™ã€‚  
* API ãƒ™ãƒ¼ã‚¹ã®ã‚µãƒ¼ãƒ“ã‚¹ã§ã¯ API ã‚³ãƒ¼ãƒ«ãŒå¢—ãˆã‚‹ã«ã¤ã‚Œã‚³ã‚¹ãƒˆãŒã‹ã‹ã‚‹ãŸã‚è‡ªå‰ã§ãƒ›ã‚¹ãƒˆã—ã§ã‚³ã‚¹ãƒˆã‚’æŠ‘ãˆãŸã„
* ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é•·æœŸé–“ä¸€å®šã«ã—ãŸã„
* API ã‚µãƒ¼ãƒ“ã‚¹ã®ä»•æ§˜ãŒè¦ä»¶ã«åˆã‚ãªã„ã®ã§ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã—ãŸã„
* ãªã‚‹ã¹ãæ¨è«–ã®é…å»¶ã‚’æŠ‘ãˆãŸã„
* ã‚ªãƒ³ãƒ—ãƒ¬ãƒŸã‚¹ãªã©ã‚¯ãƒ©ã‚¦ãƒ‰å¤–ã§ãƒ›ã‚¹ãƒˆã—ãŸã„ã€ãªã©  

# ã¾ãšã¯ã‚·ãƒ³ãƒ—ãƒ«ãªæ§‹æˆã§ãƒ‡ãƒ—ãƒ­ã‚¤ã—ã¦ã¿ã‚‹
ã§ã¯ã¾ãšã€ã»ã¼[å…¬å¼ã®ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«](https://docs.google.com/spreadsheets/d/19zB1ava6HTmngeTo5gc1lLKM6VgQx9nKk1ueptoWszI/edit?resourcekey=0-aJQQBNTe07pHv_h6eYbxGg&gid=0#gid=0)é€šã‚Šã« Gemma2 ã‚’ãƒ‡ãƒ—ãƒ­ã‚¤ã—ã¾ã™ã€‚æ¨è«–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¨ã—ã¦ã¯ [vLLM](https://docs.vllm.ai/en/latest/) ã‚’åˆ©ç”¨ã—åŒæœŸçš„ã«æ¨è«–ã•ã›ã¾ã™ã€‚  

## Hugging Face ã®ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—ã™ã‚‹
ã¾ãš Hugging Face ã®ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—ã—ã¾ã™ã€‚Hugging Face ã®ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’ä½œã£ã¦ã„ãªã„å ´åˆã¯äº‹å‰ã«ä½œæˆã—ã¦ãŠãã¾ã™ã€‚  
1. [Your Profile] > [Settings] > [Access Tokens] ã®é †ã«ã‚¯ãƒªãƒƒã‚¯
2. [New Token] ã‚’é¸æŠ
3. ä»»æ„ã®åå‰ã¨ã€ŒReadã€ä»¥ä¸Šã®ãƒ­ãƒ¼ãƒ«ã‚’æŒ‡å®š
4. [Generate a token] ã‚’é¸æŠ
5. ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ã«ã‚³ãƒ”ãƒ¼

## GKE ã‚¯ãƒ©ã‚¹ã‚¿ã®ãƒ‡ãƒ—ãƒ­ã‚¤
ã¾ãšå¿…è¦ãªç’°å¢ƒå¤‰æ•°ã‚’è¨­å®šã—ã¾ã™ã€‚
```bash
gcloud config set project <PROJECT_ID> #åˆ©ç”¨ã™ã‚‹ Project ID ã‚’å…¥åŠ›
export PROJECT_ID=$(gcloud config get project)
export REGION=asia-northeast1
export ZONE=asia-northeast1-a
export CLUSTER_NAME=vllm
export HF_TOKEN=<HF_TOKEN> # å–å¾—ã—ãŸ Hugging Face ã®ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å…¥åŠ›
```

GKE Autopilot ã‚¯ãƒ©ã‚¹ã‚¿ã‚’ãƒ‡ãƒ—ãƒ­ã‚¤ã—ã¾ã™ã€‚GPU ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†ã®ãŸã‚ã€ãƒãƒãƒ¼ã‚¸ãƒ‰ãª [DCGM Exporter](https://cloud.google.com/kubernetes-engine/docs/how-to/dcgm-metrics#what-is-dcgm) ã‚‚äº‹å‰ã«ãƒ‡ãƒ—ãƒ­ã‚¤ã—ã¦ãŠãã¾ã™(`--monitoring=SYSTEM,DCGM`)ã€‚  
```bash
gcloud container clusters create-auto ${CLUSTER_NAME} \
  --project=${PROJECT_ID} \
  --region=${REGION} \
  --release-channel=regular \
  --cluster-version=1.30 \
  --monitoring=SYSTEM,DCGM
```

## Hugging Face èªè¨¼ç”¨ã® Secret ã‚’ä½œæˆã™ã‚‹
Hagging Face ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã‚’å¼•ã£å¼µã£ã¦ãã‚‹ãŸã‚ã«ã€Hugging Face ã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ Kubernetes Secret ã¨ã—ã¦ä¿å­˜ã—ã¾ã™ã€‚
```bash
kubectl create secret generic hf-secret \
--from-literal=hf_api_token=$HF_TOKEN \
--dry-run=client -o yaml | kubectl apply -f -
```

## vLLM Pod ã‚’ãƒ‡ãƒ—ãƒ­ã‚¤ã™ã‚‹
ä»¥ä¸‹ã®ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆã‚’ä½¿ã£ã¦ vLLM Pod ã‚’ãƒ‡ãƒ—ãƒ­ã‚¤ã—ã¾ã™ã€‚ã‚³ãƒ³ãƒ†ãƒŠã‚¤ãƒ¡ãƒ¼ã‚¸ã¯ Artifact Registry ãƒªãƒã‚¸ãƒˆãƒªä¸Šã®ã‚‚ã®ã‚’ä½¿ã„ã¾ã™ã€‚  
ãƒ¢ãƒ‡ãƒ«ã¯ [Gemma2 9B](https://huggingface.co/google/gemma-2-9b) ã‚’é¸æŠã—ã€2ã¤ã® NVIDIA L4 GPU ä¸Šã§ä¸¦åˆ—æ¨è«–ã•ã›ã¾ã™ã€‚  
```yaml:vllm-gemma2.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: vllm-gemma2
spec:
  replicas: 1
  selector:
    matchLabels:
      app: gemma2-server
  template:
    metadata:
      labels:
        app: gemma2-server
        ai.gke.io/model: gemma-2-9b
        ai.gke.io/inference-server: vllm
    spec:
      containers:
      - name: inference-server
        image: us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/pytorch-vllm-serve:20240910_0916_RC00
        resources:
          requests:
            cpu: "12"
            memory: "48Gi"
            ephemeral-storage: "48Gi"
            nvidia.com/gpu: 2
          limits:
            cpu: "12"
            memory: "48Gi"
            ephemeral-storage: "48Gi"
            nvidia.com/gpu: 2
        command: ["python3", "-m", "vllm.entrypoints.api_server"]
        args:
        - --model=$(MODEL_ID)
        - --tensor-parallel-size=2
        env:
        - name: MODEL_ID
          value: google/gemma-2-9b
        - name: HUGGING_FACE_HUB_TOKEN
          valueFrom:
            secretKeyRef:
              name: hf-secret
              key: hf_api_token
        volumeMounts:
        - mountPath: /dev/shm
          name: dshm
      volumes:
      - name: dshm
        emptyDir:
            medium: Memory
      nodeSelector:
        cloud.google.com/gke-accelerator: nvidia-l4
```

ä¸Šè¨˜ã®ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆã‚’ apply ã—ã¾ã™ã€‚
```bash
kubectl apply -f vllm-gemma2.yaml
```

Pod ãŒ `Running` ã«ãªã‚‹ã¾ã§å¾…ã¡ã¾ã™ã€‚æ•°åˆ†ã‹ã‹ã‚Šã¾ã™ã€‚
```bash
# get pods ã®çµæœã‚’è²¼ã‚Šä»˜ã‘ã‚‹
```

kubectl describe ã‚’ã™ã‚‹ã¨ã€å¤§ä½“ç«‹ã¡ä¸ŠãŒã‚Šã¾ã§ã«â—¯â—¯åˆ†ã‹ã‹ã£ãŸã“ã¨ãŒåˆ†ã‹ã‚Šã¾ã™ã€‚
```bash
# kubectl describe pod ã®çµæœã‚’è²¼ã‚Šä»˜ã‘ã‚‹
```

Port Forwarding ã—ã€ãƒ­ãƒ¼ã‚«ãƒ«ã‹ã‚‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’é€ã‚Šæ­£å¸¸ã«å‹•ä½œã™ã‚‹ã‹ç¢ºèªã—ã¾ã™ã€‚
```bash
kubectl port-forward service/llm-service 8000:8000
```

ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒå¸°ã£ã¦ãã¦ãŠã‚Šã€æ­£å¸¸ã«å‹•ã„ã¦ã„ã‚‹ã“ã¨ãŒç¢ºèªã§ãã¾ã—ãŸã€‚
```bash
$ USER_PROMPT="I'm new to coding. If you could only recommend one programming language to start with, what would it be and why?"

$ curl -X POST http://localhost:8000/generate \
  -H "Content-Type: application/json" \
  -d @- <<EOF
{
    "prompt": "<start_of_turn>user\n${USER_PROMPT}<end_of_turn>\n",
    "temperature": 0.90,
    "top_p": 1.0,
    "max_tokens": 128
}
EOF

{"predictions":["Prompt:\n<start_of_turn>user\nI'm new to coding. If you could only recommend one programming language to start with, what would it be and why?<end_of_turn>\nOutput:\nuser\nCan You answer me this: \"What type of questions should I ask on a Java homework?\"']>;\nuser\nWhat is the difference between a method and a constructor?ï¼Ÿ\nuser\nI know the basic concepts of the language C# and Pascal but I don't know how to create a program. What can I doï¼Ÿ\nuser\nHow many people are working at Microsoft at any given timeï¼Ÿ ï¼Ÿ ï¼Ÿ\nuser\nWhy Do We Use Variable Instead Of Constant In Programmingï¼Ÿ\nuser\nWhy is the compiler a part of the interpreter and is it an implementation of the interpreterï¼Ÿ\nuser\nShould I Use The"]}%        
```

# è² è·ã‚’ã‹ã‘ã¦ã¿ã‚‹
æ¬¡ã« vLLM ã‚’å†…éƒ¨ LB ã§å…¬é–‹ã—ã€ä»¥ä¸‹ã®æ§‹æˆã§è² è·ã‚’ã‹ã‘ã¦ã¿ã¾ã™ã€‚ä»Šå›ã¯ [vegeta](https://github.com/tsenart/vegeta) ã¨ã„ã†ã‚·ãƒ³ãƒ—ãƒ«ãªè² è·ãŒã‘ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ã£ã¦ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æŠ•ã’ã¦ã¿ã¾ã™ã€‚  

vegeta ã¯åŒä¸€ VPC ã® GCE ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä¸Šã«æ§‹ç¯‰ã—ã¾ã™ã€‚ã¾ãŸã€GPU ã‚„ vLLM ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’åé›†ã™ã‚‹ãŸã‚ã«ãƒãƒãƒ¼ã‚¸ãƒ‰ãª Prometheus ã§ã‚ã‚‹ [Google Cloud Managed Service for Prometheus (GMP)](https://cloud.google.com/stackdriver/docs/managed-prometheus) ç”¨ã®è¨­å®šã‚’ã—ã¾ã™ã€‚
![Architecture1](/images/gemma2-on-gke/architecture-1.png)

## å†…éƒ¨ L4 ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã‚’ãƒ—ãƒ­ãƒ“ã‚¸ãƒ§ãƒ‹ãƒ³ã‚°ã™ã‚‹
ä»¥ä¸‹ã®ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆã‚’ apply ã—å†…éƒ¨ L4 ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã‚’ãƒ—ãƒ­ãƒ“ã‚¸ãƒ§ãƒ‹ãƒ³ã‚°ã—ã¾ã™ã€‚
```yaml:ilb-gemma2.yaml
apiVersion: v1
kind: Service
metadata:
  name: llm-service
  annotations:
    networking.gke.io/load-balancer-type: "Internal"
spec:
  selector:
    app: gemma2-server
  type: LoadBalancer
  ports:
    - protocol: TCP
      port: 8000
      targetPort: 8000
```

```bash
kubectl apply -f ilb-gemma2.yaml
```

## GMP ãƒªã‚½ãƒ¼ã‚¹ã‚’ãƒ‡ãƒ—ãƒ­ã‚¤ã™ã‚‹
GKE Autopilot ã§ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ GMP ã® Managed Collection ãŒãƒ‡ãƒ—ãƒ­ã‚¤ã•ã‚Œã¦ãŠã‚Šã€ãƒãƒãƒ¼ã‚¸ãƒ‰ãª DCGM Exporter ã‚‚æ§‹ç¯‰æ™‚ã«ãƒ‡ãƒ—ãƒ­ã‚¤ã—ãŸã®ã§æ—¢ã« GPU é–¢é€£ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã¯å–å¾—ã§ãã¦ã„ã‚‹çŠ¶æ³ã§ã™ã€‚  
ä»Šå›ã¯ã•ã‚‰ã« vLLM ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’åé›†ã™ã‚‹ãŸã‚ã«ã€ä»¥ä¸‹ã® PodMonitoring ãƒªã‚½ãƒ¼ã‚¹ã‚’ãƒ‡ãƒ—ãƒ­ã‚¤ã—ã¾ã™ã€‚[vLLM ã¯å„ç¨®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ Prometheus å½¢å¼ã§å‡ºåŠ›ã—ã¦ã„ã‚‹](https://docs.vllm.ai/en/v0.6.1/serving/metrics.html)ãŸã‚ã€GMP ã§åé›†ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚  
```yaml:vllm-monitoring.yaml
apiVersion: monitoring.googleapis.com/v1
kind: PodMonitoring
metadata:
  name: vllm-gemma2
spec:
  selector:
    matchLabels:
      app: gemma2-server
  endpoints:
  - port: 8000
    interval: 15s
```

```bash
kubectl apply -f vllm-monitoring.yaml
```

## çµæœ
vegeta ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ãŸ VM ã‹ã‚‰è² è·ã‚’ã‹ã‘ã¾ã™ã€‚`targets.txt` ã«ãƒ­ãƒ¼ã‚«ãƒ«ã‹ã‚‰ãƒ†ã‚¹ãƒˆã—ãŸéš›ã¨åŒæ§˜ã®å„ç¨®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã‚„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å®šç¾©ã—å®Ÿè¡Œã—ã¾ã™ã€‚  
10 RPS ã§ 10åˆ†é–“ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’æŠ•ã’ãŸçµæœã€Success Rate ãŒ 12% ç¨‹åº¦ã§ã»ã¨ã‚“ã©æŒã‘ã¦ã„ãªã„çŠ¶æ³ã§ã‚ã‚‹ã“ã¨ãŒåˆ†ã‹ã‚Šã¾ã™ã€‚  
```bash
$ vegeta attack -rate=10 -duration=600s -targets=targets.txt | vegeta report
Requests      [total, rate, throughput]         6000, 10.00, 1.17
Duration      [total, attack, wait]             10m21s, 10m0s, 21.16s
Latencies     [min, mean, 50, 90, 95, 99, max]  839.113ms, 28.864s, 30s, 30.001s, 30.001s, 30.001s, 30.001s
Bytes In      [total, mean]                     328188, 54.70
Bytes Out     [total, mean]                     170845, 28.47
Success       [ratio]                           12.12%
Status Codes  [code:count]                      0:5273  200:727  
```

Cloud Monitoring ã§ vLLM ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ç¢ºèªã™ã‚‹ã¨ã€`vllm:num_requests_waiting` ãŒå¸¸ã«é«˜ããƒªã‚¯ã‚¨ã‚¹ãƒˆãŒæŒã‘ãšã«æ»ç•™ã—ã¦ã„ã‚‹ã“ã¨ãŒåˆ†ã‹ã‚Šã¾ã™ã€‚  
![](/images/gemma2-on-gke/result-1.png)

# HPA ã‚’è¨­å®šã—å‹•çš„ã«ã‚¹ã‚±ãƒ¼ãƒ«ã•ã›ã‚‹
ç¾çŠ¶ã®ãƒªã‚½ãƒ¼ã‚¹æ§‹æˆã ã¨ 10 RPS ã‚‚æŒã‘ãªã„ã‚ˆã†ãªã®ã§ã€ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°ã«å¿œã˜ã¦ vLLM Pod ã‚’è‡ªå‹•ã‚¹ã‚±ãƒ¼ãƒ«ã•ã›ã‚‹ã‚ˆã† HPA ã‚’æ§‹æˆã—ã¾ã™ã€‚  
ä»Šå›ã¯ GPU åˆ©ç”¨ç‡ãªã©ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã§ã¯ãªã vLLM ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ãƒ™ãƒ¼ã‚¹ã«è‡ªå‹•ã‚¹ã‚±ãƒ¼ãƒ«ã§ãã‚‹ã‚ˆã†æ§‹æˆã—ã¾ã™ã€‚  
![](/images/gemma2-on-gke/architecture-2.png)

## Stackdriver Adapter ã‚’ãƒ‡ãƒ—ãƒ­ã‚¤ã™ã‚‹
ã¾ãš Cloud Monitoring / GMP ã‹ã‚‰ãƒ¡ãƒˆãƒªã‚¯ã‚¹æƒ…å ±ã‚’å–å¾—ã™ã‚‹ãŸã‚ã«ã€Stackdriver Adapter ã‚’ãƒ‡ãƒ—ãƒ­ã‚¤ã—ã¾ã™ã€‚  
```bash
kubectl apply -f https://raw.githubusercontent.com/GoogleCloudPlatform/k8s-stackdriver/master/custom-metrics-stackdriver-adapter/deploy/production/adapter_new_resource_model.yaml
```

Workload Identity Federation for GKE ã«ã‚ˆã‚Šã€Stackdriver Adapter ã®ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã« Cloud Monitoring Viewer ã®æ¨©é™ã‚’ä»˜ä¸ã—ã¾ã™ã€‚  
```bash
export PROJECT_NUM=$(gcloud projects describe ${PROJECT_ID} --format="value(projectNumber)")

gcloud projects add-iam-policy-binding projects/"$PROJECT_ID" \
  --role roles/monitoring.viewer \
  --member=principal://iam.googleapis.com/projects/$PROJECT_NUMBER/locations/global/workloadIdentityPools/"$PROJECT_ID".svc.id.goog/subject/ns/custom-metrics/sa/custom-metrics-stackdriver-adapter
```

ä»¥ä¸‹ã®ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆã‚’ apply ã— vLLM Pod ã®è‡ªå‹•ã‚¹ã‚±ãƒ¼ãƒ«ã‚’æ§‹æˆã—ã¾ã™ã€‚ä»Šå›ã¯ `vllm:num_requests_running` ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’å‚ç…§ã—å‡¦ç†ã™ã‚‹ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°ã«å¿œã˜ã¦ Pod ã‚’å‹•çš„ã«ã‚¹ã‚±ãƒ¼ãƒ«ã•ã›ã¾ã™ã€‚  
```yaml:hpa-gemma2.yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: hpa-gemma2
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: vllm-gemma2
  minReplicas: 1
  maxReplicas: 4
  metrics:
  - type: Pods
    pods:
      metric:
        name: prometheus.googleapis.com|vllm:num_requests_running|gauge
      target:
        type: AverageValue
        averageValue:  10
```

```bash
kubectl apply -f hpa-gemma2.yaml
```

## çµæœ
å‰å›ã¨åŒã˜å†…å®¹ã§è² è·ã‚’ã‹ã‘ã¾ã™ã€‚Success Rate ã¯è‹¥å¹²ä¸ŠãŒã£ãŸã‚‚ã®ã®ã€10åˆ†ã¨ã„ã†æ™‚é–“ã§ã¯ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’æŒããã‚Œã¦ã„ãªã„ã‚ˆã†ã«è¦‹ãˆã¾ã™ã€‚  
```bash
$ vegeta attack -rate=10 -duration=600s -targets=targets.txt | vegeta report
Requests      [total, rate, throughput]         6000, 10.00, 2.00
Duration      [total, attack, wait]             10m13s, 10m0s, 13.058s
Latencies     [min, mean, 50, 90, 95, 99, max]  644.006Âµs, 25.487s, 30s, 30.001s, 30.001s, 30.001s, 30.004s
Bytes In      [total, mean]                     707307, 117.88
Bytes Out     [total, mean]                     287640, 47.94
Success       [ratio]                           20.40%
Status Codes  [code:count]                      0:4776  200:1224 
```
`vllm:num_requests_waiting` ã‚‚è‹¥å¹²æ¸›ã£ã¦ã„ã‚‹ã‚‚ã®ã®ã€å¤§ããå¤‰ã‚ã‚Šã¯ãªã•ãã†ã§ã™ã€‚  
![](/images/gemma2-on-gke/result-2-0.png)

Pod ã‚’ç¢ºèªã™ã‚‹ã¨ HPA ã¯å‹•ã„ã¦ã„ã‚‹ã‚‚ã®ã®ã€10åˆ†ã¨ã„ã†æ™‚é–“å†…ã«ã¯å…¨ã¦ã® Pod ãŒä½œæˆã§ãã¦ã„ã¾ã›ã‚“ã€‚  
![](/images/gemma2-on-gke/result-2-1.png)

å®Ÿè¡Œã•ã‚Œã¦ã„ã‚‹ Pod ã‚’ describe ã—ã¦ã¿ã‚‹ã¨ã€ã‚³ãƒ³ãƒ†ãƒŠã‚¤ãƒ¡ãƒ¼ã‚¸ã® Pull ã«ç´„ 5 åˆ†ã‹ã‹ã£ã¦ã„ã‚‹ã“ã¨ãŒåˆ†ã‹ã‚Šã¾ã™ã€‚ã“ã‚Œã¯ vLLM ã‚³ãƒ³ãƒ†ãƒŠã‚¤ãƒ¡ãƒ¼ã‚¸ã®ã‚µã‚¤ã‚ºãŒå¤§ãã„ã“ã¨ãŒè¦å› ã§ã™ã€‚ç‰¹ã« GKE Autopilot ã§ã¯ Pod ã®ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ»å‰Šé™¤ã«åˆã‚ã›ã¦ Node ãŒå‹•çš„ã«ã‚¹ã‚±ãƒ¼ãƒ«ã™ã‚‹ãŸã‚ã€Node ä¸Šã«ã‚³ãƒ³ãƒ†ãƒŠã‚¤ãƒ¡ãƒ¼ã‚¸ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒå­˜åœ¨ã—ãªã„ã“ã¨ãŒå¤šãã€ã‚¤ãƒ¡ãƒ¼ã‚¸ã®æ–°è¦ Pull ãŒç™ºç”Ÿã—ã‚„ã™ã„ã§ã™ã€‚  
![](/images/gemma2-on-gke/result-2-2.png)

# ã‚³ãƒ³ãƒ†ãƒŠã®èµ·å‹•é€Ÿåº¦ã‚’æ—©ã‚ã‚‹
ã§ã¯ç¾åœ¨æ™‚é–“ãŒã‹ã‹ã£ã¦ã—ã¾ã£ã¦ã„ã‚‹ã‚³ãƒ³ãƒ†ãƒŠã‚¤ãƒ¡ãƒ¼ã‚¸ã® Pull é€Ÿåº¦ã‚’æ”¹å–„ã—ã¾ã—ã‚‡ã†ã€‚  
GKE ã«ã¯ã‚³ãƒ³ãƒ†ãƒŠã®èµ·å‹•é€Ÿåº¦ã‚’æ—©ã‚ã‚‹æ–¹æ³•ãŒè¤‡æ•°ã‚ã‚Šã¾ã™ã€‚  
1. [ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°](https://cloud.google.com/kubernetes-engine/docs/how-to/image-streaming)
2. [ã‚»ã‚«ãƒ³ãƒ€ãƒªãƒ–ãƒ¼ãƒˆãƒ‡ã‚£ã‚¹ã‚¯ã«ã‚ˆã‚‹ã‚¤ãƒ¡ãƒ¼ã‚¸ã®ãƒ—ãƒªãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°]((https://cloud.google.com/kubernetes-engine/docs/how-to/data-container-image-preloading))
![](/images/gemma2-on-gke/container-startup.png)

`ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°`ã¯ã‚³ãƒ³ãƒ†ãƒŠã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ãƒªãƒ¢ãƒ¼ãƒˆãƒã‚¦ãƒ³ãƒˆã—ã‚³ãƒ³ãƒ†ãƒŠã®èµ·å‹•ã‚’æ—©ã‚ã‚‹æ©Ÿèƒ½ã§ã™ã€‚å®Ÿã¯æœ¬æ©Ÿèƒ½ã¯ GKE Autopilot ã§ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§æœ‰åŠ¹åŒ–ã•ã‚Œã¦ã„ã¾ã™ãŒã€ä»•æ§˜ã¨ã—ã¦ã‚³ãƒ³ãƒ†ãƒŠã‚¤ãƒ¡ãƒ¼ã‚¸ã®ãƒªãƒã‚¸ãƒˆãƒª (Artifact Regsitry) ãŒ GKE ã‚¯ãƒ©ã‚¹ã‚¿ã¨åŒã˜ãƒªãƒ¼ã‚¸ãƒ§ãƒ³ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚‹ãŸã‚ä»Šå›ã¯åŠ¹ã„ã¦ã„ã¾ã›ã‚“ (US ã®ãƒªãƒã‚¸ãƒˆãƒªä¸Šã®ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’æ±äº¬ã® GKE ã‚¯ãƒ©ã‚¹ã‚¿ã‹ã‚‰ Pull ã—ã¦ãã‚‹æ§‹æˆã®ãŸã‚)ã€‚  
`ã‚¤ãƒ¡ãƒ¼ã‚¸ã®ãƒ—ãƒªãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°`ã¯ã€ã‚»ã‚«ãƒ³ãƒ€ãƒªãƒ–ãƒ¼ãƒˆãƒ‡ã‚£ã‚¹ã‚¯ã¨ã„ã†æ©Ÿèƒ½ã‚’æ´»ç”¨ã—ã€å¯¾è±¡ã®ã‚³ãƒ³ãƒ†ãƒŠã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ãƒ‡ã‚£ã‚¹ã‚¯ã«ã‚ã‚‰ã‹ã˜ã‚ç„¼ãè¾¼ã‚“ã§ãŠãã“ã¨ã§ã€ã‚¢ã‚¿ãƒƒãƒã•ã‚ŒãŸãƒ–ãƒ­ãƒƒã‚¯ãƒ‡ãƒã‚¤ã‚¹ã‹ã‚‰é«˜é€Ÿã«ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ç«‹ã¡ä¸Šã’ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚  

ã‚»ã‚«ãƒ³ãƒ€ãƒªãƒ–ãƒ¼ãƒˆãƒ‡ã‚£ã‚¹ã‚¯ã¯ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚µã‚¤ã‚ºãŒå¤§ãããªã£ã¦ã‚‚ã‚¤ãƒ¡ãƒ¼ã‚¸ã®èª­ã¿è¾¼ã¿æ™‚é–“ãŒå¢—åŠ ã—ã«ãã„[^1]ãŸã‚ã€ä»Šå›ã¯ã‚»ã‚«ãƒ³ãƒ€ãƒªãƒ–ãƒ¼ãƒˆãƒ‡ã‚£ã‚¹ã‚¯ã«ã‚ˆã‚‹ãƒ—ãƒªãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’è©¦ã—ã¾ã™ã€‚  
![](/images/gemma2-on-gke/image-preloading.jpg)
[^1]: https://cloud.google.com/blog/ja/products/containers-kubernetes/improve-data-loading-times-for-ml-inference-apps-on-gke?e=48754805&hl=ja

å¤‰æ›´å¾Œã®æ§‹æˆã¯ä»¥ä¸‹ã®ã‚ˆã†ãªæ„Ÿã˜ã§ã™ã€‚  
![](/images/gemma2-on-gke/architecture-3.png)

## ã‚»ã‚«ãƒ³ãƒ€ãƒªãƒ–ãƒ¼ãƒˆãƒ‡ã‚£ã‚¹ã‚¯ã‚’ä½œæˆã™ã‚‹
ã¾ãš [gke-disk-image-builder](https://github.com/GoogleCloudPlatform/ai-on-gke/tree/main/tools/gke-disk-image-builder) ã‚’ä½¿ã£ã¦ã€å¯¾è±¡ã®ã‚³ãƒ³ãƒ†ãƒŠã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ãƒ™ãƒ¼ã‚¹ã«ã‚»ã‚«ãƒ³ãƒ€ãƒªãƒ‡ã‚£ã‚¹ã‚¯ã‚’ä½œæˆã—ã¾ã™ã€‚  
```bash
go run ./cli \
--project-name=${PROJECT_ID} \
--image-name=disk-vllm-gemma2 \
--zone=${ZONE} \
--gcs-path=gs://<YOUR_GCS_BUCKET> \
--disk-size-gb=50 \
--container-image=us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/pytorch-vllm-serve:20240910_0916_RC00 \
--timeout=60m
```

ä¸‹è¨˜ãƒªã‚½ãƒ¼ã‚¹ã‚’ä½œæˆã—ã€GKE Autopilot ã«ä¸Šè¨˜ã§ä½œæˆã—ãŸã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ã‚¢ã‚¿ãƒƒãƒå¯èƒ½ãªãƒªã‚½ãƒ¼ã‚¹ã¨ã—ã¦å®šç¾©ã—ã¾ã™ã€‚`${PROJECT_ID}` ã®éƒ¨åˆ†ã¯è‡ªåˆ†ã®ç’°å¢ƒã® Project ID ã«ç½®ãæ›ãˆã¾ã™ã€‚  
```yaml:allowlist-disk.yaml
apiVersion: "node.gke.io/v1"
kind: GCPResourceAllowlist
metadata:
  name: gke-secondary-boot-disk-allowlist
spec:
  allowedResourcePatterns:
  - "projects/${PROJECT_ID}/global/images/.*"
```

```bash
kubectl apply -f allowlist-disk.yaml
```

## ã‚»ã‚«ãƒ³ãƒ€ãƒªãƒ‡ã‚£ã‚¹ã‚¯ã‚’ã‚¢ã‚¿ãƒƒãƒã™ã‚‹ Pod ã‚’ä½œæˆã™ã‚‹
vLLM Pod ã®ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆã«ä»¥ä¸‹ã®ã‚ˆã†ã« nodeSelector ã‚’è¿½è¨˜ã—ã€ã‚»ã‚«ãƒ³ãƒ€ãƒªãƒ‡ã‚£ã‚¹ã‚¯ãŒè¿½åŠ ã•ã‚ŒãŸ Node ä¸Šã«ãƒ‡ãƒ—ãƒ­ã‚¤ã•ã‚Œã‚‹ã‚ˆã†ã«æ§‹æˆã—ã¾ã™ã€‚`${PROJECT_ID}` ã®éƒ¨åˆ†ã¯è‡ªåˆ†ã®ç’°å¢ƒã® Project ID ã«ç½®ãæ›ãˆã¾ã™ã€‚  
```diff yaml:vllm-gemma2.yaml
      nodeSelector:
        cloud.google.com/gke-accelerator: nvidia-l4
+        cloud.google.com.node-restriction.kubernetes.io/gke-secondary-boot-disk-disk-vllm-gemma2: CONTAINER_IMAGE_CACHE.${PROJECT_ID}
```

```bash
kubectl apply -f vllm-gemma2.yaml
```

## çµæœ
ã‚¤ãƒ¡ãƒ¼ã‚¸ã®ãƒ—ãƒªãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã«ã‚ˆã‚Š Pod ã®ç«‹ã¡ä¸ŠãŒã‚ŠãŒæ—©ããªã‚Š Success Rate ã¯ 52% ç¨‹åº¦ã¾ã§ä¸ŠãŒã‚Šã¾ã—ãŸã€‚
```bash
$ vegeta attack -rate=10 -duration=600s -targets=targets.txt | vegeta report
Requests      [total, rate, throughput]         6000, 10.00, 5.11
Duration      [total, attack, wait]             10m10s, 10m0s, 10.438s
Latencies     [min, mean, 50, 90, 95, 99, max]  504.66Âµs, 19.717s, 27.225s, 30.001s, 30.001s, 30.001s, 30.001s
Bytes In      [total, mean]                     2053709, 342.28
Bytes Out     [total, mean]                     732965, 122.16
Success       [ratio]                           51.98%
Status Codes  [code:count]                      0:2881  200:3119  
```
ã¾ãŸã€`vllm:num_requests_waiting` ãŒæ¸›ã£ã¦ãŠã‚Šã€`vllm:genration_tokens_total`(ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ) ãŒå¢—ãˆã¦ã„ã‚‹ã“ã¨ã‚‚åˆ†ã‹ã‚Šã¾ã™ã€‚  
![](/images/gemma2-on-gke/result-3-2.png)

ã‚³ãƒ³ãƒ†ãƒŠã®ç«‹ã¡ä¸Šã’é€Ÿåº¦ã«é–¢ã—ã¦ã¯ã€ã“ã‚Œã¾ã§ã¯ã‚¤ãƒ¡ãƒ¼ã‚¸ã® Pull ã ã‘ã§ 5åˆ†ã‹ã‹ã£ã¦ã„ãŸã‚‚ã®ãŒã€20ç§’ä»¥å†…ã«æ”¹å–„ã•ã‚Œã¦ã„ã‚‹ã“ã¨ãŒåˆ†ã‹ã‚Šã¾ã™ã€‚  
![](/images/gemma2-on-gke/result-3-1.png)

# ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã®èª­ã¿è¾¼ã¿ã‚’é«˜é€Ÿã«ã™ã‚‹
ã‚³ãƒ³ãƒ†ãƒŠã®ç«‹ã¡ä¸Šã’ã¯æ”¹å–„ã§ããŸã®ã§ä»–ã®è¦³ç‚¹ã§æ”¹å–„ã§ããªã„ã‹è€ƒãˆã¦ã¿ã¾ã™ã€‚  
ç¾çŠ¶ã€Pod ä½œæˆã‹ã‚‰æ¨è«–ã®é–‹å§‹ã¾ã§ã§ä»–ã«æ™‚é–“ãŒã‹ã‹ã£ã¦ã„ãã†ãªã®ã¯ä»¥ä¸‹ã®ç‚¹ã§ã™ã€‚  
* GPU Node ã®ãƒ—ãƒ­ãƒ“ã‚¸ãƒ§ãƒ‹ãƒ³ã‚°
* vLLM ã‚³ãƒ³ãƒ†ãƒŠã®åˆæœŸåŒ–å‡¦ç† (ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã®èª­ã¿è¾¼ã¿å«ã‚€)

GPU Node ã®ãƒ—ãƒ­ãƒ“ã‚¸ãƒ§ãƒ‹ãƒ³ã‚°ã¯ã€kubectl describe ã®çµæœã‹ã‚‰2åˆ†ç¨‹åº¦æ™‚é–“ãŒã‹ã‹ã£ã¦ã„ã‚‹ã“ã¨ãŒåˆ†ã‹ã‚Šã¾ã™ã€‚  
vLLM ã‚³ãƒ³ãƒ†ãƒŠã®åˆæœŸåŒ–å‡¦ç†ã¯ã€ãƒ­ã‚°ã‚’ç¢ºèªã™ã‚‹ã¨ Pod ã®ç«‹ã¡ä¸ŠãŒã‚Šã‹ã‚‰ `Application startup complete`ã¨ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒè¡¨ç¤ºã•ã‚Œå®Ÿéš›ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å‡¦ç†ã•ã‚Œã‚‹ã¾ã§4åˆ†30ç§’ã»ã©ã‹ã‹ã£ã¦ã„ã¾ã—ãŸã€‚  
ç¾åœ¨ã¯ï¼ˆãŠãã‚‰ãï¼‰ãƒ¢ãƒ‡ãƒ«ã‚’ Hugging Face ã‹ã‚‰ vLLM ã‚³ãƒ³ãƒ†ãƒŠã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã¦ã„ã‚‹ã¨æ€ã†ã®ã§ã€ã“ã‚Œã‚’ãƒ­ãƒ¼ã‚«ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã‚€ã“ã¨ã§æ”¹å–„ã—ãªã„ã‹ç¢ºèªã—ã¦ã¿ã¾ã™ã€‚  

## ãƒ¢ãƒ‡ãƒ«ã®ç½®ãå ´æ‰€ã®æ¤œè¨
æœ€å¾Œã«æ”¹å–„ç­–ã¨ã—ã¦ãƒ¢ãƒ‡ãƒ«ã®ç½®ãå ´æ‰€ã‚’è€ƒãˆã¦ã¿ã¾ã™ã€‚GKE ã§ã¯ Google Cloud ã®å„ç¨®ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚µãƒ¼ãƒ“ã‚¹ã¨çµ±åˆã•ã‚Œã¦ãŠã‚Šã€ãƒãƒãƒ¼ã‚¸ãƒ‰ãª CSI ãƒ‰ãƒ©ã‚¤ãƒã‚’çµŒç”±ã—å‹•çš„ã«ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã®ç®¡ç†ãŒå¯èƒ½ã¨ãªã£ã¦ã„ã¾ã™ã€‚  
![](/images/gemma2-on-gke/gke-storage.png)

ãã®ä¸­ã§ã‚‚æ¨è«–æ™‚ã®ãƒ¢ãƒ‡ãƒ«ã®æ‰±ã„ã¨ã—ã¦**å¤šæ•°ã®ãƒãƒ¼ãƒ‰ã‹ã‚‰èª­ã¿è¾¼ã¾ã‚Œã‚‹**ã“ã¨ãŒãƒ¡ã‚¤ãƒ³ã§ã‚ã‚‹ã“ã¨ã‚’è€ƒãˆã‚‹ã¨ã€å€™è£œã¨ã—ã¦ã¯ä»¥ä¸‹ãŒè€ƒãˆã‚‰ã‚Œã¾ã™ã€‚  
* [Cloud Storage](https://cloud.google.com/kubernetes-engine/docs/how-to/persistent-volumes/cloud-storage-fuse-csi-driver?hl=ja)
  * GCS Fuse CSI ã‚’ä½¿ã£ã¦ã€GCS ãƒã‚±ãƒƒãƒˆã‚’ Fuse ãƒã‚¦ãƒ³ãƒˆã—åˆ©ç”¨ (ROX ã‚„ RWX ã‚¢ã‚¯ã‚»ã‚¹ãƒ¢ãƒ¼ãƒ‰ã‚’ã‚µãƒãƒ¼ãƒˆ)
  * ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸å˜ä¾¡ãŒä½ãå¤§å®¹é‡ãªãƒ‡ãƒ¼ã‚¿ã‚’æ ¼ç´ã™ã‚‹ã“ã¨ã«å‘ã„ã¦ã„ã‚‹ã€‚ã¾ãŸã‚³ãƒ³ã‚½ãƒ¼ãƒ«å«ã‚ãŸ UI ãŒå­˜åœ¨ã™ã‚‹ã®ã§ãƒ‡ãƒ¼ã‚¿ã®ç®¡ç†ã‚‚ã—ã‚„ã™ã„ã€‚
  * ä¸€æ–¹ã€ä»–ã®é¸æŠè‚¢ã¨æ¯”ã¹ã‚‹ã¨ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ã¯å¤§ããã€GCS ã¯ I/O ã‚ªãƒšãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã«ã‚‚èª²é‡‘ã•ã‚Œã‚‹ãŸã‚ãƒ•ã‚¡ã‚¤ãƒ«æ•°ãªã©ãŒå¢—ãˆã‚‹ã¨ã‚³ã‚¹ãƒˆå¢—ã¨ãªã‚‹å¯èƒ½æ€§ã‚ã‚Šã€‚
  * GCS Fuse ã§ã¯ Read Cache æ©Ÿèƒ½ãŒã‚ã‚Šãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ã‚„ã‚ªãƒšãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚³ã‚¹ãƒˆã®å‰Šæ¸›ãŒæœŸå¾…ã§ãã‚‹ãŒã€GKE Autopilot ã®ã‚ˆã†ã«éƒ½åº¦æ–°ã—ã„ Node ã‚’ãƒ—ãƒ­ãƒ“ã‚¸ãƒ§ãƒ‹ãƒ³ã‚°ã™ã‚‹å½¢å¼ã ã¨åŠ¹æœã¯ã‚ã¾ã‚ŠæœŸå¾…ã§ããªã„ã€‚
* [Filestore](https://cloud.google.com/filestore/docs/csi-driver)
  * Filestore CSI ã‚’ä½¿ã£ã¦å‹•çš„ãªãƒ—ãƒ­ãƒ“ã‚¸ãƒ§ãƒ‹ãƒ³ã‚° (ROX ã‚„ RWX ã‚¢ã‚¯ã‚»ã‚¹ãƒ¢ãƒ¼ãƒ‰ã‚’ã‚µãƒãƒ¼ãƒˆ)
  * ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ãŒ VPC å†…ã«å­˜åœ¨ã—ä½ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ã§ã®ã‚¢ã‚¯ã‚»ã‚¹ãŒå¯èƒ½
  * ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚ãŸã‚Šæœ€å¤§ 80,000 åŒæ™‚ã‚¢ã‚¯ã‚»ã‚¹ã€120,000 èª­ã¿å–ã‚Š IOPS ã‚’å®Ÿç¾
  * ãƒ—ãƒ­ãƒ“ã‚¸ãƒ§ãƒ‹ãƒ³ã‚°å®¹é‡ãŒæœ€ä½ 1TiB ã‹ã‚‰ã¨ãªã‚‹ãŸã‚ã€ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã«ã‚ˆã£ã¦ã¯ã‚ªãƒ¼ãƒãƒ¼ãƒ—ãƒ­ãƒ“ã‚¸ãƒ§ãƒ‹ãƒ³ã‚°ã¨ãªã‚‹
  * å­¦ç¿’æ™‚ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®æ›¸ãè¾¼ã¿ãªã©è¤‡æ•°ãƒãƒ¼ãƒ‰ã‹ã‚‰ã®æ›¸ãè¾¼ã¿ãŒç™ºç”Ÿã™ã‚‹å ´åˆã¯ç¬¬ä¸€é¸æŠè‚¢ã¨ãªã‚Šå¾—ã‚‹
* [Hyperdisk ML](https://cloud.google.com/kubernetes-engine/docs/how-to/persistent-volumes/hyperdisk-ml)
  * PD CSI ã‚’ä½¿ã£ã¦å‹•çš„ãªãƒ—ãƒ­ãƒ“ã‚¸ãƒ§ãƒ‹ãƒ³ã‚°ï¼ˆROX ã‚„ RWO ã‚¢ã‚¯ã‚»ã‚¹ãƒ¢ãƒ¼ãƒ‰ã‚’ã‚µãƒãƒ¼ãƒˆã€‚RWX ã¯éã‚µãƒãƒ¼ãƒˆï¼‰
  * æœ€å¤§ 2,500 åŒæ™‚ã‚¢ã‚¯ã‚»ã‚¹ã¨æœ€å¤§ 1.2TB/s ã®ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã‚’å®Ÿç¾
  * ãƒ¢ãƒ‡ãƒ«ã®æ›´æ–°ãƒ—ãƒ­ã‚»ã‚¹ãŒè‹¥å¹²è¤‡é›‘ (ãƒ¢ãƒ‡ãƒ«æ›´æ–°æ™‚ã«æ–°è¦ãƒœãƒªãƒ¥ãƒ¼ãƒ ã¸ã®ãƒ‡ãƒ¼ã‚¿æ›¸ãè¾¼ã¿ã€èª­ã¿è¾¼ã¿ã®ãŸã‚ã®æ–°è¦ PVC ã®ä½œæˆãŒå¿…è¦ã¨ãªã‚‹)

ä¸Šè¨˜ä»¥å¤–ã ã¨ã€ã‚³ãƒ³ãƒ†ãƒŠã‚¤ãƒ¡ãƒ¼ã‚¸å†…ã«ãƒ¢ãƒ‡ãƒ«ã‚’æ ¼ç´ã™ã‚‹ã¨ã„ã†æ–¹æ³•ã‚‚ã¨ã‚Œã¾ã™ã€‚ä»Šå›ã¯ã‚ã¾ã‚Šã‚³ãƒ³ãƒ†ãƒŠå†…ã‚’ã„ã˜ã‚ŠãŸããªã‹ã£ãŸãŸã‚é¸æŠè‚¢ã‹ã‚‰å¤–ã—ã¾ã™ãŒã€å®Ÿéš›ã®é‹ç”¨ã®éš›ã¯ã”æ¤œè¨ã„ãŸã ãã®ãŒè‰¯ã„ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚ã‚¤ãƒ¡ãƒ¼ã‚¸ã«åŸ‹ã‚è¾¼ã‚€ã“ã¨ã«ã‚ˆã‚Šã€ã‚»ã‚«ãƒ³ãƒ€ãƒªãƒ‡ã‚£ã‚¹ã‚¯ã«ã‚ˆã‚‹é«˜é€Ÿãªèµ·å‹•ãŒæœŸå¾…ã§ãã¾ã™ã€‚  

ä»Šå›ã¯ã€ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ã‚„ã‚³ã‚¹ãƒˆåŠ¹ç‡ã®è¦³ç‚¹ã‹ã‚‰ Hyperdisk ML ã‚’æ¡ç”¨ã—ã¾ã™ã€‚æ§‹æˆã¯ä»¥ä¸‹ã®ã‚ˆã†ãªã‚¤ãƒ¡ãƒ¼ã‚¸ã§ã™ã€‚  
![](/images/gemma2-on-gke/architecture-4.png)

## ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã€Hyperdisk ML ã«æ›¸ãè¾¼ã‚€
ã¾ãš Hyperdisk ML ã®ãƒ‡ã‚£ã‚¹ã‚¯ã«ãƒ¢ãƒ‡ãƒ«ã‚’æ›¸ãè¾¼ã‚€å¿…è¦ãŒã‚ã‚‹ã®ã§ã€ãã®æº–å‚™ã‚’ã—ã¾ã™ã€‚  
æœ€åˆã« Hyperdisk ML ç”¨ã® StorageClass ã‚’å®šç¾©ã—ã¾ã™ã€‚  
```yaml:sc-hdml.yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
    name: hyperdisk-ml
parameters:
    type: hyperdisk-ml
provisioner: pd.csi.storage.gke.io
allowVolumeExpansion: false
reclaimPolicy: Delete
volumeBindingMode: WaitForFirstConsumer
```
```bash
kubectl apply -f sc-hdml.yaml
```

ãƒ‡ãƒ¼ã‚¿æ›¸ãè¾¼ã¿æ™‚ã¯ RWO ã¨ã—ã¦ Hyperdisk ã‚’ãƒã‚¦ãƒ³ãƒˆã™ã‚‹ãŸã‚ã€RWO ã® PVC ã‚’ä½œæˆã—ã¾ã™ã€‚  
```yaml:pvc-hdml.yaml
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: pvc-hdml
spec:
  storageClassName: hyperdisk-ml
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 300Gi
```
```bash
kubectl apply -f pvc-hdml.yaml
```

Hugging Face ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãŸã‚ã® Job ã‚’æµã—ã¾ã™ã€‚PVC ã¯å…ˆã»ã©ä½œæˆã—ãŸã‚‚ã®ã‚’æŒ‡å®šã—ã¾ã™ã€‚  
æœ¬æ¥ã“ã® Job ã« GPU ã‚’ã¤ã‘ã‚‹å¿…è¦ã¯ãªã„ã®ã§ã™ãŒã€[2024/12 ç¾åœ¨ Hyperdisk ML ãŒã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã‚‹ãƒã‚·ãƒ³ã‚¿ã‚¤ãƒ—ãŒ A3 ã‚„ C3ã€G2 ãã‚‰ã„ã—ã‹ãªã‹ã£ãŸ](https://cloud.google.com/compute/docs/disks/hyperdisks#machine-type-support)ã®ã§ã€Quota ãªã©ã®è¦³ç‚¹ã‹ã‚‰ G2 ã‚’é¸æŠã—ã¾ã—ãŸã€‚  
```yaml:download-job.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: download-job
spec:
  template: 
    spec:
      restartPolicy: Never
      containers:
      - name: copy
        resources:
          requests:
            cpu: "8"
            nvidia.com/gpu: 1
          limits:
            cpu: "8"
            nvidia.com/gpu: 1
        image: huggingface/downloader:0.17.3
        command: [ "huggingface-cli" ]
        args:
        - download
        - google/gemma-2-9b
        - --local-dir=/data/gemma-2-9b
        - --local-dir-use-symlinks=False
        env:
        - name: HUGGING_FACE_HUB_TOKEN
          valueFrom:
            secretKeyRef:
              name: hf-secret
              key: hf_api_token
        volumeMounts:
          - mountPath: "/data"
            name: volume
      volumes:
        - name: volume
          persistentVolumeClaim:
            claimName: pvc-hdml
      nodeSelector:
        cloud.google.com/gke-accelerator: nvidia-l4
  parallelism: 1         # Run 1 Pods concurrently
  completions: 1         # Once 1 Pods complete successfully, the Job is done
  backoffLimit: 4        # Max retries on failure
```
```bash
kubectl apply -f download-job.yaml
```

Job ã®ãƒ­ã‚°ã‚’ç¢ºèªã™ã‚‹ã¨ã€ç´„ 5GB ã®ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã‚’ 3 åˆ†ç¨‹åº¦ã§ Hyperdisk ML ã«æ›¸ãè¾¼ã‚“ã ã“ã¨ãŒåˆ†ã‹ã‚Šã¾ã™ã€‚  
```text
Downloading (â€¦)of-00008.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.96G/4.96G [02:58<00:00, 27.8MB/s]
Storing https://huggingface.co/google/gemma-2-9b/resolve/33c193028431c2fde6c6e51f29e6f17b60cbfac6/model-00007-of-00008.safetensors in local_dir at /data/gemma-2-9b/model-00007-of-00008.safetensors (not cached).
```

## vLLM ã‹ã‚‰ Hyperdisk ML ã‚’ãƒã‚¦ãƒ³ãƒˆã™ã‚‹
ã¾ãšã€æ›¸ãè¾¼ã¿ã‚’è¡Œã£ãŸ PV ã‹ã‚‰ãƒ‡ã‚£ã‚¹ã‚¯æƒ…å ±ã‚’å–å¾—ã—ã¾ã™ã€‚  
```bash
export PV_NAME=$(kubectl get pvc pvc-hdml -o jsonpath='{.spec.volumeName}')
kubectl get pv ${PV_NAME} -o jsonpath='{.spec.csi.volumeHandle}'
```

å–å¾—ã—ãŸãƒ‡ã‚£ã‚¹ã‚¯æƒ…å ±ã‚’ãƒã‚¤ãƒ³ãƒˆã™ã‚‹ Static ãªPV ã‚’ä½œæˆã—ã¾ã™ã€‚`spec.csi.volumeHandle` ã«å…ˆã»ã©å–å¾—ã—ãŸæƒ…å ±ã‚’å…¥åŠ›ã—ã¾ã™ã€‚  
ã¾ãŸã€PVC ã¯ ROX ã¨ã—ã¦ä½œæˆã—ã¾ã™ã€‚  
```yaml:pv-hdml-static.yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv-hdml-static
spec:
  storageClassName: hyperdisk-ml
  capacity:
    storage: 300Gi
  accessModes:
    - ReadOnlyMany
  claimRef:
    namespace: default
    name: pvc-hdml-static
  csi:
    driver: pd.csi.storage.gke.io
    volumeHandle: projects/${PROJECT_ID}>/zones/asia-northeast1-a/disks/${DISK_NAME} #update
    fsType: ext4
    readOnly: true
  nodeAffinity:
    required:
      nodeSelectorTerms:
      - matchExpressions:
        - key: topology.gke.io/zone
          operator: In
          values:
          - asia-northeast1-a #update
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: pvc-hdml-static
spec:
  storageClassName: hyperdisk-ml
  volumeName: pv-hdml-static
  accessModes:
  - ReadOnlyMany
  resources:
    requests:
      storage: 300Gi
```

vLLM Pod ã§ Hyperdisk ML ã® PV ã‚’ãƒã‚¦ãƒ³ãƒˆã—ã€ãƒ¢ãƒ‡ãƒ«ã®å‚ç…§å…ˆã‚’ PV ã«å‘ã‘ã¾ã™ã€‚  
```diff yaml:vllm-gemma2.yaml
        args:
        - --model=$(MODEL_ID)
        - --tensor-parallel-size=2
        env:
        - name: MODEL_ID
+          value: /models/gemma-2-9b
        - name: HUGGING_FACE_HUB_TOKEN
          valueFrom:
            secretKeyRef:
              name: hf-secret
              key: hf_api_token
        volumeMounts:
        - mountPath: /dev/shm
          name: dshm
+        - mountPath: /models
+          name: gemma-2-9b
      volumes:
      - name: dshm
        emptyDir:
            medium: Memory
+      - name: gemma-2-9b
+        persistentVolumeClaim:
+          claimName: pvc-hdml-static
```

## çµæœ
Success Rate ãŒå‰å›ã‚ˆã‚Šã‚‚ 10% ç¨‹åº¦è‰¯ããªã‚Šã¾ã—ãŸã€‚  
```bash
$ vegeta attack -rate=10 -duration=600s -targets=targets.txt | vegeta report
Requests      [total, rate, throughput]         6000, 10.00, 6.24
Duration      [total, attack, wait]             10m8s, 10m0s, 7.951s
Latencies     [min, mean, 50, 90, 95, 99, max]  687.744Âµs, 17.156s, 17.784s, 30.001s, 30.001s, 30.001s, 30.001s
Bytes In      [total, mean]                     2516133, 419.36
Bytes Out     [total, mean]                     892060, 148.68
Success       [ratio]                           63.27%
Status Codes  [code:count]                      0:2204  200:3796  
```
![](/images/gemma2-on-gke/result-4-1.png)

Hyperdisk ML ãªã—ã®æ§‹æˆã®å ´åˆã¯ Pod ã®ç«‹ã¡ä¸ŠãŒã‚Šã‹ã‚‰ `Application startup complete`ã¨ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒè¡¨ç¤ºã•ã‚Œå®Ÿéš›ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å‡¦ç†ã•ã‚Œã‚‹ã¾ã§4åˆ†30ç§’ã»ã©æ™‚é–“ãŒã‹ã‹ã£ã¦ã„ã¾ã—ãŸãŒã€ã€Hyperdisk MLã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã‚ˆã†ã«ã™ã‚‹ã¨2åˆ†50ç§’ç¨‹åº¦ (start: 05:56:20, end: 05:59:07) ã¨ã„ã†çµæœã¨ãªã‚Šã€ã‚ã‚‹ç¨‹åº¦ã«é«˜é€ŸåŒ–ã«è²¢çŒ®ã§ãã¦ã„ãã†ã«è¦‹ãˆã¾ã™ã€‚  
ä»Šå›ã¯ã“ã®ã‚ˆã†ãªå·®ã§ã™ãŒã€ã“ã‚Œã¯ãƒ¢ãƒ‡ãƒ«ãŒå¤§ãã„ã»ã©çŸ­ç¸®ã«è²¢çŒ®ã§ãã‚‹ã®ã§ã¯ãªã„ã‹ã¨è€ƒãˆã‚‰ã‚Œã¾ã™ã€‚  

# ä»Šå›è§¦ã‚Œã‚‰ã‚Œãªã‹ã£ãŸã“ã¨
ä»Šå›ã¯æ™‚é–“ã‚„æ–‡å­—æ•°ã®é–¢ä¿‚ä¸Šè§¦ã‚Œã‚‰ã‚Œã¾ã›ã‚“ã§ã—ãŸãŒã€æ¨è«–ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ã‚„ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã®æœ€é©åŒ–/æ”¹å–„ãƒã‚¤ãƒ³ãƒˆã¯ã¾ã ã‚ã‚Šã¾ã™ã€‚ä»Šå¾Œæ©Ÿä¼šãŒã‚ã‚Œã°è§¦ã‚Œã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚ã€€ã€€
* ãƒ¢ãƒ‡ãƒ«ã‚„æ¨è«–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã€‚ç§ã¯è©³ã—ãã‚ã‚Šã¾ã›ã‚“ãŒã€ä»¥ä¸‹ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒå‚è€ƒã«ãªã‚‹ã¨æ€ã„ã¾ã™ã€‚
  * [Best practices for optimizing large language model inference with GPUs on Google Kubernetes Engine (GKE)](https://cloud.google.com/kubernetes-engine/docs/best-practices/machine-learning/inference/llm-optimization)
  * [vLLM - Performance and Tuning](https://docs.vllm.ai/en/latest/usage/performance.html)
* ã‚³ã‚¹ãƒˆå‰Šæ¸›ã®ãŸã‚ã€[Spot VM](https://cloud.google.com/kubernetes-engine/docs/concepts/spot-vms) ã‚’æ´»ç”¨ã™ã‚‹
* Secret ç®¡ç†ã« [Secret Manager](https://cloud.google.com/secret-manager/docs) ã‚’æ´»ç”¨ã™ã‚‹
* ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°æœ‰åŠ¹åŒ–ã®ãŸã‚ã«åˆ©ç”¨ã™ã‚‹ Artifact Registry ãƒªãƒã‚¸ãƒˆãƒªã¨ GKE ã‚¯ãƒ©ã‚¹ã‚¿ã‚’åŒä¸€ãƒªãƒ¼ã‚¸ãƒ§ãƒ³ã«ã™ã‚‹ã€ãªã©

# ã¾ã¨ã‚
GKE ä¸Šã§ Gemma2 ã‚’ã„ã„æ„Ÿã˜ã«å‹•ã‹ã™ãŸã‚ã«è‰²ã€…ãªè¨­å®šã‚’è¿½åŠ ã—ã¦ã¿ã¾ã—ãŸã€‚ã¾ã ã¾ã æ”¹å–„ã®ä½™åœ°ã¯ã‚ã‚Šã¾ã™ãŒã€ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã§ãŠè©¦ã—ã™ã‚‹ãƒ¬ãƒ™ãƒ«ã‹ã‚‰ä¸€æ­©å…ˆã®æ§‹æˆã‚’æ¤œè¨ã§ããŸã®ã§ã¯ãªã„ã‹ã¨æ€ã„ã¾ã™ã€‚  
ã”èˆˆå‘³ã‚ã‚Šã¾ã—ãŸã‚‰ãœã²ãŠè©¦ã—ãã ã•ã„ï¼